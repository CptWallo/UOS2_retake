{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection \n",
    "For the classification of 'bank deposit sales calls'the model should suit teh following characterstiscs\n",
    "1-Binary Classification: Outcome call yes=deposit sales call successful, no==deposit sales call failed\n",
    "2-Features 15, both categorical and numerical\n",
    "3-no sequence in data, all instances are indipendent of eachother\n",
    "4-a high Recall takes priority over  ‘Precision’ (True Positive as high as possible , while accepting some False Positives , which will result in high recall and a lower Precision). This is due to the nature of the classification, we want to reach as many ‘Success; outcome as possible, accepting that some will eventually be ‘Failures’ \n",
    "5-Hyperparamets should be present and tunable\n",
    "\n",
    "# Model selected: Random forest\n",
    "\n",
    "Data exploration and cleaning: removing and replacing NAN values and dropping one column with sparse values. Several feature-distributions are right skewed and needs log transformation before fitting a model. Outliers are rare and contains logical values and are mostly kept in the dataset. The feature ‘duration ‘of a call is dropped, since it cannot be known before making a call\n",
    "\n",
    "Log transform improves the base modes Accuracy from 0.88 to 0.89. Log transform is kept before tuning the base model\n",
    "\n",
    "Hyperparameter n-estimators (number of nodes in the random tree) is kept low=10, in the base model for tuning-training purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X):    age          job  marital  education default  balance housing loan  \\\n",
      "0   41  blue-collar  married    primary      no      849     yes   no   \n",
      "1   49   technician  married    primary      no     1415     yes   no   \n",
      "2   42       admin.  married  secondary      no     3842      no   no   \n",
      "3   37   management   single   tertiary      no     -119     yes   no   \n",
      "4   56  blue-collar  married    primary      no     3498      no   no   \n",
      "\n",
      "    contact  day_of_week month  campaign  pdays  previous  \n",
      "0   unknown           15   may         1     -1         0  \n",
      "1  cellular           30   jul         2     -1         0  \n",
      "2  cellular           31   jul         4     -1         0  \n",
      "3   unknown           11   jun        11     -1         0  \n",
      "4  cellular           15   apr         2     -1         0  \n",
      "Target (y): 0     no\n",
      "1     no\n",
      "2     no\n",
      "3     no\n",
      "4    yes\n",
      "Name: y, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined dataset\n",
    "csv_path = 'data/processed/train_clean.csv'\n",
    "df_train = pd.read_csv(csv_path)\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X= df_train.drop(columns=['y'])  # Assuming the target column is named 'target'\n",
    "y= df_train['y']  # Extract the target column\n",
    "\n",
    "print(\"Features (X):\", X.head())\n",
    "print(\"Target (y):\", y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "(34547,)\n",
      "(34547, 14)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model random forest without log transformation\n",
    "# Import necessary libraries\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target series\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "\n",
    "# One-hot encode categorical variables (like 'island' and 'sex')\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model random forest with log transformation\n",
    "# Import necessary libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# X = your_dataframe_with_features\n",
    "# y = your_target_variable\n",
    "\n",
    "# Add log transformation for  'campaign', and 'balance'\n",
    "for feature in ['campaign', 'balance']:\n",
    "    X[feature] = np.log1p(X[feature])  # log1p(x) = log(1 + x), safely handles zero values\n",
    "\n",
    "# One-hot encode categorical variables \n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Initialize LabelEncoder for the target variable (y)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "(34547,)\n",
      "(34547, 14)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model tuning\n",
    "\n",
    "Add gin.config file to the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rye install gin-config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hyperparameters for RandomForestClassifier\n",
    "RandomForestClassifier.n_estimators = 100\n",
    "RandomForestClassifier.max_depth = 10\n",
    "RandomForestClassifier.min_samples_split = 2\n",
    "RandomForestClassifier.min_samples_leaf = 1\n",
    "RandomForestClassifier.max_features = 'auto'\n",
    "RandomForestClassifier.bootstrap = True\n",
    "RandomForestClassifier.random_state = 42\n",
    "\n",
    "# Features to apply log transformation\n",
    "log_transform_features = ['campaign', 'balance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvallo/MADS-MachineLearning-course/.venv/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Enter interactive mode to allow re-registration of configurables\n",
    "gin.enter_interactive_mode()\n",
    "\n",
    "# Register RandomForestClassifier as a gin-configurable object\n",
    "@gin.configurable\n",
    "class ConfigurableRandomForestClassifier(RandomForestClassifier):\n",
    "    pass\n",
    "\n",
    "# Load the Gin config file\n",
    "gin.parse_config_file('telemarketing.gin')\n",
    "\n",
    "@gin.configurable\n",
    "def load_random_forest_model(\n",
    "    n_estimators=100, \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    max_features='sqrt',  # Updated 'auto' to 'sqrt'\n",
    "    bootstrap=True, \n",
    "    random_state=42):\n",
    "    \"\"\"\n",
    "    Configurable RandomForestClassifier using gin.\n",
    "    \"\"\"\n",
    "    return ConfigurableRandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "# Assume telemarketing dataset is already defined\n",
    "# X = telemarketing_dataframe\n",
    "# y = target_variable\n",
    "\n",
    "# Add log transformation for 'campaign', and 'balance'\n",
    "for feature in ['campaign', 'balance']:\n",
    "    X[feature] = np.log1p(X[feature])  # log1p(x) = log(1 + x), safely handles zero values\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Initialize LabelEncoder for the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load RandomForest model with gin-configured hyperparameters\n",
    "clf = load_random_forest_model()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Enter interactive mode to allow re-registration of configurables\n",
    "gin.enter_interactive_mode()\n",
    "\n",
    "# Register RandomForestClassifier as a gin-configurable object\n",
    "@gin.configurable\n",
    "class ConfigurableRandomForestClassifier(RandomForestClassifier):\n",
    "    pass\n",
    "\n",
    "# Load the Gin config file\n",
    "gin.parse_config_file('telemarketing.gin')\n",
    "\n",
    "@gin.configurable\n",
    "def load_random_forest_model(\n",
    "    n_estimators=100, \n",
    "    max_depth=None, \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    max_features='sqrt',  \n",
    "    bootstrap=True, \n",
    "    random_state=42):\n",
    "    return ConfigurableRandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "\n",
    "# Step 1: Check and handle negative values before applying log transformation\n",
    "X['campaign'] = X['campaign'].apply(lambda x: np.nan if x <= 0 else np.log1p(x))\n",
    "X['balance'] = X['balance'].apply(lambda x: np.nan if x <= 0 else np.log1p(x))\n",
    "\n",
    "# Step 2: Handle any remaining NaN or infinity values\n",
    "# Option 1: Fill NaN values with 0 (or a specific value like the column median)\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "# Option 2: Remove rows with NaN or infinity values (if desired)\n",
    "# X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# X.dropna(inplace=True)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Initialize LabelEncoder for the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load RandomForest model with gin-configured hyperparameters\n",
    "clf = load_random_forest_model()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
